{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from probability import normal_cdf, inverse_normal_cdf\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# z = a_b_test_statistic(1000, 200, 1000, 180)    # -1.14\\n# The probability of seeing such a large difference if the means were actually equal would be:\\n# two_sided_p_value(z)     # 0.254\\n# which is large enough that you can\\xe2\\x80\\x99t conclude there\\xe2\\x80\\x99s much of a difference. \\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: cp1252 -*-\n",
    "#***************************************************************************************************\n",
    "#**********************Chapter 7. Hypothesis and Inference****************************************\n",
    "#***************************************************************************************************\n",
    "\n",
    "# Example: Flipping a Coin\n",
    "# Imagine we have a coin and we want to test whether it’s fair. We’ll make the assumption that the coin has some \n",
    "# probability p of landing heads, and so our null hypothesis is that the coin is fair — that is, that p=0.5. \n",
    "# We will test this against the alternative hypothesis p != .5. In particular, our test will involve flipping the coin \n",
    "# some number n times and counting the number of heads X. Each coin flip is a Bernoulli trial, which means \n",
    "# that X is a Binomial(n,p) random variable, which (as we saw in Chapter 6) we can approximate using the normal distribution:\n",
    "\n",
    "def normal_approximation_to_binomial(n, p):\n",
    "    \"\"\"finds mu and sigma corresponding to a Binomial(n, p)\"\"\"\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(p * (1 - p) * n)\n",
    "    return mu, sigma\n",
    "\n",
    "# the normal cdf _is_ the probability the variable is below a threshold\n",
    "normal_probability_below = normal_cdf\n",
    "\n",
    "# it's above the threshold if it's not below the threshold\n",
    "def normal_probability_above(lo, mu=0, sigma=1):\n",
    "    return 1 - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# it's between if it's less than hi, but not less than lo\n",
    "def normal_probability_between(lo, hi, mu=0, sigma=1):\n",
    "    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# it's outside if it's not between\n",
    "def normal_probability_outside(lo, hi, mu=0, sigma=1):\n",
    "    return 1 - normal_probability_between(lo, hi, mu, sigma)\n",
    "\n",
    "# We can also do the reverse — find either the nontail region or the (symmetric) interval around the mean that accounts \n",
    "# for a certain level of likelihood. For example, if we want to find an interval centered at the mean and containing \n",
    "# 60% probability, then we find the cutoffs where the upper and lower tails each contain 20% of the probability (leaving 60%):\n",
    "\n",
    "# ???? First understand inverse_normal_cdf in previos chapter.\n",
    "def normal_upper_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z <= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(probability, mu, sigma)\n",
    "\n",
    "def normal_lower_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z >= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(1 - probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the symmetric (about the mean) bounds that contain the specified probability\"\"\"\n",
    "    tail_probability = (1 - probability) / 2\n",
    "    # upper bound should have tail_probability above it\n",
    "    upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
    "    # lower bound should have tail_probability below it\n",
    "    lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# In particular, let’s say that we choose to flip the coin n=1000 times. If our hypothesis of fairness is true, \n",
    "# X should be distributed approximately normally with mean 500 and standard deviation 15.8: \n",
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)\n",
    "'''\n",
    "# print \"mu_0 which is n*p and sigma_0(SD) which is root[n*p*(1-p)] for 1000 tosses and prob 0.5 are %r and %r\" %(mu_0,sigma_0)\n",
    "# print normal_two_sided_bounds(0.95, mu_0, sigma_0)    O/P is (469.01026640487555, 530.9897335951244)\n",
    "# print normal_two_sided_bounds(0.95, 0, 1)             O/P is (-1.9599628448486328, 1.9599628448486328)\n",
    "'''\n",
    "\n",
    "def two_sided_p_value(x, mu=0, sigma=1):\n",
    "    if x >= mu:\n",
    "        # if x is greater than the mean, the tail is what's greater than x\n",
    "#        print normal_probability_above(x, mu, sigma)\n",
    "        return 2 * normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        # if x is less than the mean, the tail is what's less than x\n",
    "        return 2 * normal_probability_below(x, mu, sigma)\n",
    "\n",
    "# If we were to see 530 heads, we would compute:\n",
    "# print two_sided_p_value(529.5, mu_0, sigma_0)              # 0.062\n",
    "\n",
    "\n",
    "# Awesome Simulation: One way to convince yourself that this is a sensible estimate is with a simulation:\n",
    "# We flip coin 1000 time for 100000 trials and see value of the extreme_value_count / 100000 which gives \n",
    "# probability of values out of interval 470 and 530.\n",
    "\n",
    "'''\n",
    "extreme_value_count = 0\n",
    "for _ in range(100000):\n",
    "    num_heads = sum(1 if random.random() < 0.5 else 0 \t\t# count # of heads\n",
    "                    for _ in range(1000)) \t\t        # in 1000 flips\n",
    "    if num_heads >= 530 or num_heads <= 470: \t\t\t# and count how often\n",
    "        extreme_value_count += 1 \t\t\t        # the # is 'extreme'\n",
    "    print extreme_value_count / 100000 # 0.062\n",
    "'''\n",
    "\n",
    "\n",
    "# Confidence Intervals\n",
    "# main confusion comes why 1000 in this math.sqrt(p * (1 - p) / 1000).\n",
    "# 1000 comes because it shuld be sigma/root(n) for sampling distribution.\n",
    "# Here we don’t know p, so instead we use our estimate:\n",
    "'''\n",
    "p_hat = 525 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\t  # 0.0158\n",
    "print sigma\n",
    "print normal_two_sided_bounds(0.95, mu, sigma) \n",
    "'''\n",
    "\n",
    "\n",
    "# P-hacking: A procedure that erroneously rejects the null hypothesis only 5% of the time will —\n",
    "# By definition — 5% of the time erroneously reject the null hypothesis:\n",
    "def run_experiment():\n",
    "    \"\"\"flip a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
    "    return [random.random() < .5 for _ in range(1000)]\n",
    "\n",
    "def reject_fairness(experiment):\n",
    "    \"\"\"using the 5% significance levels\"\"\"\n",
    "    num_heads = len([flip for flip in experiment if flip])\n",
    "    return num_heads < 469 or num_heads > 531\n",
    "\n",
    "# random.seed(0)\n",
    "# experiments = [run_experiment() for _ in range(1000)]\n",
    "# num_rejections = len([experiment for experiment in experiments if reject_fairness(experiment)])\n",
    "# print num_rejections # 46\n",
    "\n",
    "#other way:\n",
    "def run_experiment1():\n",
    "    \"\"\"flip a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
    "    sum1 = sum([random.random() < .5 for _ in range(1000)])\n",
    "    if (sum1 > 469 and sum1 < 531):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#random.seed(0)\n",
    "#experiments1 = sum(1 - run_experiment1() for _ in range(1000))\n",
    "#print experiments1\n",
    "\n",
    "\n",
    "# Example: Running an A/B Test: It is like measuring if 2 samples belong to same population.\n",
    "def estimated_parameters(N, n):\n",
    "    p = n / N\n",
    "    sigma = math.sqrt(p * (1 - p) / N)\n",
    "    return p, sigma\n",
    "\n",
    "def a_b_test_statistic(N_A, n_A, N_B, n_B):\n",
    "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
    "    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)\n",
    "\n",
    "# For example, if “tastes great” gets 200 clicks out of 1,000 views and “less bias” gets 180 clicks out of 1,000 views, the statistic equals:\n",
    "# z = a_b_test_statistic(1000, 200, 1000, 180)\t # -1.14\n",
    "# The probability of seeing such a large difference if the means were actually equal would be:\n",
    "# For example, if 'tastes great' gets 200 clicks out of 1,000 views and 'less bias' gets 180 clicks out of 1,000 views, \n",
    "# the statistic equals:\n",
    "\n",
    "\"\"\"\n",
    "# z = a_b_test_statistic(1000, 200, 1000, 180)    # -1.14\n",
    "# The probability of seeing such a large difference if the means were actually equal would be:\n",
    "# two_sided_p_value(z)     # 0.254\n",
    "# which is large enough that you can’t conclude there’s much of a difference. \n",
    "\"\"\"\n",
    "\n",
    "# On the other hand, if 'less bias' only got 150 clicks, we would have:\n",
    "# z = a_b_test_statistic(1000, 200, 1000, 150)    # -2.94\n",
    "# two_sided_p_value(z)                            # 0.003\n",
    "# which means there's only a 0.003 probability you would see such a large difference if the ads were equally effective.\n",
    "\n",
    "\n",
    "# Bayesian Inference:\n",
    "# To do ????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
