{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: cp1252 -*-\n",
    "#***************************************************************************************************\n",
    "# **********************Chapter 6. Probability***************************************************\n",
    "\n",
    "# We could also ask about the probability of the event 'both children are girls' conditional on the event 'at least one \n",
    "# of the children is a girl' (L). Surprisingly, the answer is different from before!\n",
    "# As before, the event B and L ('both children are girls and at least one of the children is a girl') is just the event B. \n",
    "# This means we have:\n",
    "# P(B|L)=P(B,L)/P(L)= P(B)/P(L)=1/3\n",
    "# My solution: \n",
    "# P(B/L)=P(L/B)*P(B)/P(L)\n",
    "# P(L/B)=1 probability at least 1 is girl given both are girls 1.\n",
    "# P(B)=(1/2)*(1/2)=1/4 Probability that both are girls.\n",
    "# P(L)=GirlGirl+BoyGirl+GirlBoy=1/4+1/4+1/4=3/4\n",
    "# So P(B)/P(L)=(1/4)*(4/3)=1/3\n",
    "\n",
    "#Prove through program\n",
    "def randon_kid():\n",
    "    return random.choice(['boy','girl'])\n",
    "'''\n",
    "older_girl=0\n",
    "both_girls=0\n",
    "either_girl=0\n",
    "random.seed(0)\n",
    "for _ in xrange(10000):\n",
    "    older=randon_kid()\n",
    "    younger=randon_kid()\n",
    "    if older=='girl':\n",
    "        older_girl+=1\n",
    "    if older=='girl' or younger=='girl':\n",
    "        either_girl+=1\n",
    "    if older=='girl' and younger=='girl':\n",
    "        both_girls+=1\n",
    "print 'P(both girls/older girl ', both_girls/older_girl\n",
    "print 'P(both girls/either girl ', both_girls/either_girl\n",
    "'''\n",
    "\n",
    "# Expected value:\n",
    "# We will sometimes talk about the expected value of a random variable, which is the average of its values weighted\n",
    "# The coin flip variable has an expected value of 1/2 (= 0 * 1/2 + 1 * 1/2),\n",
    "# by their probabilities. P1*outcome+P2*outcome...Pn*outcome   \n",
    "# and the range(10) variable has an expected value of 4.5=(.1*0+.1*1...+.1*9)\n",
    "\n",
    "def uniform_pdf(x):\n",
    "    return 1 if x >= 0 and x < 1 else 0\n",
    "\n",
    "def uniform_cdf(x): \n",
    "    \"returns the probability that a uniform random variable is <= x\"\n",
    "    if x < 0: return 0 \t        # uniform random is never less than 0\n",
    "    elif x < 1: return x \t# e.g. P(X <= 0.4) = 0.4\n",
    "    else: return 1 \t\t# uniform random is always less than 1\n",
    "\n",
    "\n",
    "# It tells probability at a particular point. Max p should be at x=0 for mu=0 and sigma=1 as 0 will be mean.\n",
    "def normal_pdf(x, mu=0, sigma=1):  \n",
    "    sqrt_two_pi = math.sqrt(2 * math.pi)\n",
    "    return (math.exp(-(x-mu) ** 2 / 2 / sigma ** 2) / (sqrt_two_pi * sigma))\n",
    "\n",
    "# It tells probability from start to a particular point. Probability lies with some standard deviations.\n",
    "# The cumulative distribution function for the normal distribution cannot be written in an\n",
    "# using Python's math.erf:\n",
    "def normal_cdf(x, mu=0,sigma=1):\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2\n",
    "\n",
    "# Sometimes we'll need to invert normal_cdf to find the value corresponding to a specified probability.\n",
    "# There's no simple way to compute its inverse, but normal_cdf is continuous and strictly increasing, so we can use a binary search:\n",
    "# The function repeatedly bisects intervals until it narrows in on a Z that's close enough to the desired probability.\n",
    "# To do ????\n",
    "def inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):\n",
    "    \"\"\"find approximate inverse using binary search\"\"\"\n",
    "    # if not standard, compute standard and rescale\n",
    "    if mu != 0 or sigma != 1:\n",
    "        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n",
    "    low_z, low_p = -10.0, 0          # normal_cdf(-10) is (very close to) 0\n",
    "    hi_z, hi_p = 10.0, 1             # normal_cdf(10) is (very close to) 1\n",
    "    while hi_z - low_z > tolerance:\n",
    "        mid_z = (low_z + hi_z) / 2   # consider the midpoint\n",
    "        mid_p = normal_cdf(mid_z)    # and the cdf's value there\n",
    "        if mid_p < p:\n",
    "            # midpoint is still too low, search above it\n",
    "            low_z, low_p = mid_z, mid_p\n",
    "        elif mid_p > p:\n",
    "            # midpoint is still too high, search below it\n",
    "            hi_z, hi_p = mid_z, mid_p\n",
    "        else:\n",
    "            break\n",
    "    return mid_z\n",
    "\n",
    "\n",
    "# An easy way to illustrate this is by looking at binomial random variables, which have two parameters n and p. \n",
    "# A Binomial(n,p) random variable is simply the sum of n independent Bernoulli(p) random variables, \n",
    "# each of which equals 1 with probability p and 0 with probability 1-p:\n",
    "def bernoulli_trial(p):\n",
    "    return 1 if random.random() < p else 0\n",
    "\n",
    "def binomial(n, p):\n",
    "    return sum(bernoulli_trial(p) for _ in range(n))\n",
    "\n",
    "# 75 should have most value.\n",
    "'''\n",
    "data=Counter([binomial(100, .75) for _ in range(100)])\n",
    "print data\n",
    "'''\n",
    "\n",
    "\n",
    "# ???? Later\n",
    "def make_hist(p, n, num_points):\n",
    "    data = [binomial(n, p) for _ in range(num_points)]\n",
    "    # use a bar chart to show the actual binomial samples\n",
    "    histogram = Counter(data)\n",
    "    plt.bar([x - 0.4 for x in histogram.keys()],\n",
    "            [v / num_points for v in histogram.values()],\n",
    "            0.8,\n",
    "            color='0.75')\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(n * p * (1 - p))\n",
    "    # use a line chart to show the normal approximation\n",
    "    xs = range(min(data), max(data) + 1)\n",
    "    ys = [normal_cdf(i + 0.5, mu, sigma) - normal_cdf(i - 0.5, mu, sigma)\n",
    "            for i in xs]\n",
    "    plt.plot(xs,ys)\n",
    "    plt.title(\"Binomial Distribution vs. Normal Approximation\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
