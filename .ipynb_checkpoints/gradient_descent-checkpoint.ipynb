{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter\n",
    "from linear_algebra import distance, vector_subtract, scalar_multiply\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: cp1252 -*- \n",
    "#***************************************************************************************************\n",
    "# **********************Chapter 8. Gradient Descent*******************************************\n",
    "#***************************************************************************************************\n",
    "\n",
    "# NOTE:\n",
    "# If a function has a unique global minimum, this procedure is likely to find it.\n",
    "# If a function has multiple (local) minima, this procedure might 'find' the wrong one of them,\n",
    "# in which case you might re-run the procedure from a variety of starting points.\n",
    "# If a function has no minimum, then it's possible the procedure might go on forever.\n",
    "\n",
    "\n",
    "# Estimating the Gradient:\n",
    "# If f is a function of one variable, its derivative at a point x measures how f(x) changes when \n",
    "# we make a very small change to x.\n",
    "# It is defined as the limit of the difference quotients:\n",
    "\n",
    "def difference_quotient(f,x,h):\n",
    "    return (f(x+h)-f(x))/h     # as h approaches zero.\n",
    "\n",
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "# has the derivative. This is other way than doing difference_quotient for a very small h.\n",
    "def derivative(x):\n",
    "    return 2*x\n",
    "\n",
    "derivative_estimate=partial(difference_quotient,square,h=.000001)\n",
    "'''\n",
    "x=range(-10,10)\n",
    "y1=map(derivative,x)\n",
    "y2=map(derivative_estimate,x)\n",
    "print 'y1 is ', y1\n",
    "print 'y2 is ', y2\n",
    "'''\n",
    "\n",
    "# When f is a function of many variables, it has multiple partial derivatives, each indicating how f changes\n",
    "# when we make small changes in just one of the input variables. We calculate its ith partial derivative by treating \n",
    "# it as a function of just its ith variable, holding the other variables fixed:\n",
    "\n",
    "def partial_difference_quotient(f, v, i, h):\n",
    "    \"\"\"compute the ith partial difference quotient of f at v\"\"\"\n",
    "    w = [v_j + (h if j == i else 0) # add h to just the ith element of v\n",
    "            for j, v_j in enumerate(v)]\n",
    "    return (f(w) - f(v)) / h\n",
    "\n",
    "# after which we can estimate the gradient the same way:\n",
    "def estimate_gradient(f, v, h=0.00001):\n",
    "    return [partial_difference_quotient(f, v, i, h)\n",
    "                for i, _ in enumerate(v)]\n",
    "\n",
    "\n",
    "# NOTE:\n",
    "# A major drawback to this \"estimate using difference quotients\" approach is that it's computationally expensive.\n",
    "# If v has length n, estimate_gradient has to evaluate f on 2n different inputs.\n",
    "# If you're repeatedly estimating gradients. you're doing a whole lot of extra work.\n",
    "\n",
    "\n",
    "# Using the Gradient:\n",
    "# It's easy to see that the sum_of_squares function is smallest when its input v is a vector of zeroes.\n",
    "# But imagine we didn't know that. Let's use gradients to find the minimum among all three-dimensional vectors.\n",
    "# We'll just pick a random starting point and then take tiny steps in the opposite direction of the gradient\n",
    "# until we reach a point where the gradient is very small:\n",
    "\n",
    "def step(v, gradient, step_size):\n",
    "    \"\"\"move step_size in the direction from v\"\"\"\n",
    "    return[v_i+step_size*gradient_i for v_i,gradient_i in zip(v,gradient)]\n",
    "\n",
    "def sum_of_squares_gradient(v):\n",
    "    \"\"\"derivative of sum of squares function at a point\"\"\"\n",
    "    return [2*v_i for v_i in v]\n",
    "'''\n",
    "# pick a random starting point\n",
    "v = [random.randint(-10,10) for i in range(3)]\n",
    "tolerance = 0.0000001\n",
    "print 'start v is ', v\n",
    "'''\n",
    "\n",
    "'''\n",
    "while True:\n",
    "    global v\n",
    "    gradient = sum_of_squares_gradient(v)\n",
    "    next_v = step(v,gradient,-0.001)           \n",
    "    if distance(next_v,v) < tolerance:\n",
    "        break\n",
    "    v=next_v\n",
    "# print 'minima is at', v\n",
    "'''\n",
    "\n",
    "\n",
    "# It is possible that certain step sizes will result in invalid inputs for our function. So we'll need to create\n",
    "# a \"safe apply\" function that returns infinity (which should never be the minimum of anything) for invalid inputs:\n",
    "\n",
    "# ????\n",
    "def safe(f):\n",
    "    \"\"\"return a new function that's the same as f, except that it outputs infinity whenever f produces an error\"\"\"\n",
    "    def safe_f(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            return float('inf') # this means \"infinity\" in Python\n",
    "    return safe_f\n",
    "\n",
    "# Putting It All Together:\n",
    "# In the general case, we have some target_fn that we want to minimize, and we also have its gradient_fn.\n",
    "# For example, the target_fn could represent the errors in a model as a function of its parameters,\n",
    "# and we might want to find the parameters that make the errors as small as possible.\n",
    "# Furthermore, let's say we have (somehow) chosen a starting value for the parameters theta_0.\n",
    "# Then we can implement gradient descent as:\n",
    "\n",
    "# ???? Below can be tested on a function.\n",
    "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    \"\"\"use gradient descent to find theta that minimizes target function\"\"\"\n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    theta = theta_0             # set theta to initial value\n",
    "    target_fn = safe(target_fn) # safe version of target_fn\n",
    "    value = target_fn(theta)    # value we're minimizing\n",
    "    while True:\n",
    "        gradient = gradient_fn(theta)\n",
    "        next_thetas = [step(theta, gradient, -step_size)\n",
    "                        for step_size in step_sizes]\n",
    "        # choose the one that minimizes the error function\n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_theta)\n",
    "        # stop if we're \"converging\"\n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return theta\n",
    "        else:\n",
    "            theta, value = next_theta, next_value\n",
    "\n",
    "# We called it minimize_batch because, for each gradient step, it looks at the entire data set\n",
    "# (because target_fn returns the error on the whole data set).\n",
    "# In the next section, we'll see an alternative approach that only looks at one data point at a time.\n",
    "# Sometimes we'll instead want to maximize a function, which we can do by minimizing its negative\n",
    "# (which has a corresponding negative gradient):\n",
    "\n",
    "# ???? Below ones\n",
    "def negate(f):\n",
    "    \"\"\"return a function that for any input x returns -f(x)\"\"\"\n",
    "    return lambda *args, **kwargs: -f(*args, **kwargs)\n",
    "\n",
    "def negate_all(f):\n",
    "    \"\"\"the same when f returns a list of numbers\"\"\"\n",
    "    return lambda *args, **kwargs: [-y for y in f(*args, **kwargs)]\n",
    "\n",
    "def maximize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    return minimize_batch(negate(target_fn),\n",
    "                            negate_all(gradient_fn),\n",
    "                            theta_0,\n",
    "                            tolerance)\n",
    "\n",
    "\n",
    "# Stochastic Gradient Descent:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
